"""Main Flask application for Spendsight."""
from flask import Flask, render_template, request, jsonify, redirect, url_for, flash
from werkzeug.utils import secure_filename
import os
import sys
import json
import secrets
import logging
from pathlib import Path
from backend.config import Config, BASE_DIR

# Get the logger that was set up in run.py (don't create new handlers)
logger = logging.getLogger('spendsight')
# Don't add handlers here - they're already set up in run.py
# Just ensure we propagate to root logger which run.py configured
logger.propagate = True
from backend.parsers.chase_parser import ChaseParser
from backend.parsers.discover_parser import DiscoverParser
from backend.parsers.csv_detector import CSVDetector, CSVType
from backend.sheets.sheets_client import SheetsClient
from backend.analytics.categorizer import TransactionCategorizer
from backend.analytics.insights import InsightsGenerator
from backend.analytics.expense_classifier import ExpenseClassifier
from backend.models.category_rule import rule_engine, CategoryRule
from backend.models.exclusion_rule import exclusion_engine, ExclusionRule
from backend.models.recurring_expense import recurring_expense_engine, RecurringExpense
from backend.models.period_notes import period_notes_engine

# Initialize Flask app
app = Flask(__name__, 
            template_folder='../frontend/templates',
            static_folder='../frontend/static')
app.config.from_object(Config)

# Initialize directories
Config.init_app()

# Global storage for transactions (in production, use a database)
all_transactions = []

# Lock to prevent duplicate simultaneous requests
import threading
_load_sheets_lock = threading.Lock()
_load_sheets_in_progress = False

def needs_setup():
    """Check if the application needs initial setup."""
    # Always look for .env relative to the application base directory
    env_file = BASE_DIR / '.env'
    
    # Check if .env exists
    if not env_file.exists():
        return True
    
    # Check if Google Sheets ID is configured
    if not Config.GOOGLE_SHEETS_ID or Config.GOOGLE_SHEETS_ID.strip() == '':
        return True
    
    # Check if credentials file exists
    if not Config.GOOGLE_CREDENTIALS_PATH.exists():
        return True
    
    return False

def write_env_file(sheet_id, credentials_path='credentials.json', secret_key=None):
    """Write the .env file with configuration."""
    # Write .env next to the executable (PyInstaller) or project root (source)
    env_file = BASE_DIR / '.env'
    
    # Generate secret key if not provided
    if not secret_key or secret_key.strip() == '':
        secret_key = secrets.token_hex(32)
    
    env_content = f"""# Spendsight Environment Configuration
# Auto-generated by setup wizard

# Google Sheets Configuration
GOOGLE_SHEETS_ID={sheet_id}
GOOGLE_CREDENTIALS_PATH={credentials_path}

# Flask Configuration
FLASK_SECRET_KEY={secret_key}
FLASK_ENV=development
FLASK_DEBUG=True

# Upload Configuration
UPLOAD_FOLDER=data/uploads
MAX_CONTENT_LENGTH=16777216

# Port Configuration
PORT=5000
"""
    
    env_file.write_text(env_content, encoding='utf-8')
    return True

def allowed_file(filename):
    """Check if file extension is allowed."""
    return '.' in filename and \
           filename.rsplit('.', 1)[1].lower() in Config.ALLOWED_EXTENSIONS

def is_duplicate_transaction(new_transaction, existing_transactions):
    """Check if a transaction already exists based on date, description, and amount."""
    for existing in existing_transactions:
        # Check if all key fields match
        if (existing.transaction_date == new_transaction.transaction_date and
            existing.description == new_transaction.description and
            abs(existing.amount - new_transaction.amount) < 0.01 and  # Float comparison tolerance
            existing.bank == new_transaction.bank):
            return True
    return False

def filter_duplicates(new_transactions, existing_transactions):
    """Filter out duplicate transactions and return unique ones with duplicate count."""
    unique_transactions = []
    duplicate_count = 0
    
    for new_tx in new_transactions:
        if is_duplicate_transaction(new_tx, existing_transactions):
            duplicate_count += 1
        else:
            unique_transactions.append(new_tx)
    
    return unique_transactions, duplicate_count

@app.before_request
def log_request():
    """Log incoming requests for debugging."""
    import logging
    logger = logging.getLogger('spendsight')
    if not request.endpoint or not request.endpoint.startswith('static'):
        logger.info(f"Request: {request.method} {request.path}")

@app.before_request
def check_setup():
    """Redirect to setup if configuration is incomplete."""
    # Skip check for static files and setup routes
    setup_endpoints = ['setup', 'setup_submit', 'upload_credentials', 'check_credentials', 'restart_server']
    if request.endpoint and (request.endpoint.startswith('static') or 
                             request.endpoint in setup_endpoints):
        return None
    
    # Check if setup is needed
    if needs_setup():
        return redirect(url_for('setup'))

@app.route('/setup')
def setup():
    """Initial setup wizard."""
    # Check if credentials already exist
    creds_exist = Config.GOOGLE_CREDENTIALS_PATH.exists()
    return render_template('setup.html', credentials_exist=creds_exist)

@app.route('/setup/upload-credentials', methods=['POST'])
def upload_credentials():
    """Handle credentials JSON file upload."""
    if 'credentials_file' not in request.files:
        return jsonify({'success': False, 'error': 'No file uploaded'}), 400
    
    file = request.files['credentials_file']
    
    if file.filename == '':
        return jsonify({'success': False, 'error': 'No file selected'}), 400
    
    # Check file extension
    if not file.filename.endswith('.json'):
        return jsonify({'success': False, 'error': 'Please upload a JSON file'}), 400
    
    try:
        # Save to base directory as credentials.json
        credentials_path = BASE_DIR / 'credentials.json'
        file.save(str(credentials_path))
        
        # Extract the service account email from the credentials file
        service_account_email = None
        try:
            with open(credentials_path, 'r', encoding='utf-8') as f:
                creds_data = json.load(f)
                service_account_email = creds_data.get('client_email', '')
        except:
            pass
        
        return jsonify({
            'success': True, 
            'message': 'Credentials uploaded successfully',
            'service_account_email': service_account_email
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/setup/check-credentials')
def check_credentials():
    """Check if credentials file exists and return service account email."""
    creds_path = Config.GOOGLE_CREDENTIALS_PATH
    exists = creds_path.exists()
    service_account_email = None
    error_msg = None
    
    if exists:
        try:
            with open(creds_path, 'r', encoding='utf-8') as f:
                creds_data = json.load(f)
                service_account_email = creds_data.get('client_email')
                if not service_account_email:
                    error_msg = 'client_email not found in credentials file'
        except json.JSONDecodeError as e:
            error_msg = f'Invalid JSON in credentials file: {e}'
        except Exception as e:
            error_msg = f'Error reading credentials: {e}'
    else:
        error_msg = f'Credentials file not found at {creds_path}'
    
    return jsonify({
        'exists': exists,
        'service_account_email': service_account_email,
        'error': error_msg,
        'path': str(creds_path)
    })

@app.route('/setup/submit', methods=['POST'])
def setup_submit():
    """Handle setup form submission."""
    sheet_id = request.form.get('sheet_id', '').strip()
    
    # Validate sheet ID
    if not sheet_id:
        flash('Please provide a Google Sheet ID', 'error')
        return redirect(url_for('setup'))
    
    # Check if credentials file exists
    if not Config.GOOGLE_CREDENTIALS_PATH.exists():
        flash('Please upload your credentials.json file first', 'error')
        return redirect(url_for('setup'))
    
    # Write .env file
    try:
        write_env_file(sheet_id, 'credentials.json')
        # Return the complete page - it will trigger a restart
        return render_template('setup_complete.html', sheet_id=sheet_id)
    except Exception as e:
        flash(f'Error during setup: {str(e)}', 'error')
        return redirect(url_for('setup'))

@app.route('/setup/restart', methods=['POST'])
def restart_server():
    """Apply new configuration without server restart.
    
    Instead of actually restarting, we reload the Config in-place.
    This provides a seamless experience - no manual restart needed,
    even for PyInstaller executables.
    """
    try:
        # Reload configuration from the newly written .env file
        Config.reload()
        
        # Update Flask app config with new values
        app.config['SECRET_KEY'] = Config.SECRET_KEY
        
        return jsonify({
            'status': 'ready',
            'message': 'Configuration loaded successfully'
        })
    except Exception as e:
        return jsonify({
            'status': 'error',
            'message': f'Failed to reload configuration: {str(e)}'
        }), 500

@app.route('/loading')
def loading():
    """Loading page while fetching data from Google Sheets."""
    return render_template('loading.html')


@app.route('/api/load-from-sheets', methods=['POST'])
def api_load_from_sheets():
    """Load transactions from Google Sheets into memory with optional date filtering."""
    global all_transactions, _load_sheets_in_progress
    from datetime import datetime, timedelta
    from dateutil.relativedelta import relativedelta
    import time
    
    logger.info("API: load-from-sheets called")
    
    # Prevent duplicate simultaneous requests
    with _load_sheets_lock:
        if _load_sheets_in_progress:
            logger.info("API: load-from-sheets already in progress, skipping duplicate request")
            return jsonify({'success': False, 'error': 'Load already in progress'})
        _load_sheets_in_progress = True
    
    try:
        # Get date range from request
        data = request.get_json() or {}
        date_range = data.get('date_range', 'all_time')
        logger.info(f"API: date_range={date_range}")
        
        # Calculate start date based on date_range
        start_date = None
        today = datetime.now().date()
        
        if date_range == 'last_month':
            # Start from beginning of last month
            first_of_this_month = today.replace(day=1)
            start_date = (first_of_this_month - relativedelta(months=1))
        elif date_range == 'last_year':
            # Start from 1 year ago
            start_date = today - relativedelta(years=1)
        elif date_range == 'last_3_years':
            # Start from 3 years ago
            start_date = today - relativedelta(years=3)
        # 'all_time' leaves start_date as None
        
        logger.info(f"API: Creating SheetsClient, Config.GOOGLE_SHEETS_ID={Config.GOOGLE_SHEETS_ID[:20] if Config.GOOGLE_SHEETS_ID else 'None'}...")
        for handler in logger.handlers:
            handler.flush()
        
        sheets_client = SheetsClient()
        
        if not sheets_client.is_connected():
            return jsonify({
                'success': False,
                'error': sheets_client.last_error or 'Could not connect to Google Sheets'
            })
        
        result = sheets_client.load_transactions(start_date=start_date)
        
        if 'error' in result and result['error']:
            return jsonify({
                'success': False,
                'error': result['error']
            })
        
        loaded_transactions = result.get('transactions', [])
        
        if len(loaded_transactions) == 0:
            return jsonify({
                'success': False,
                'no_data': True,
                'message': 'No transactions found in Google Sheets'
            })
        
        # Replace in-memory transactions with loaded data
        all_transactions = loaded_transactions
        
        logger.info(f"API: load-from-sheets success - loaded {len(loaded_transactions)} transactions")
        
        _load_sheets_in_progress = False
        return jsonify({
            'success': True,
            'loaded_count': len(loaded_transactions),
            'error_count': result.get('error_count', 0),
            'date_range': date_range,
            'start_date': start_date.isoformat() if start_date else None
        })
        
    except Exception as e:
        logger.error(f"API: load-from-sheets error - {str(e)}")
        import traceback
        logger.error(traceback.format_exc())
        _load_sheets_in_progress = False
        return jsonify({
            'success': False,
            'error': str(e)
        })
    finally:
        _load_sheets_in_progress = False


@app.route('/api/upload-csv', methods=['POST'])
def api_upload_csv():
    """API endpoint to upload and process CSV files (same as upload page but returns JSON)."""
    global all_transactions
    
    # Check if files were uploaded
    if 'files' not in request.files:
        return jsonify({'success': False, 'error': 'No files uploaded'})
    
    files = request.files.getlist('files')
    category_source = request.form.get('category_source', 'csv')
    
    # Filter out empty file inputs
    files = [f for f in files if f.filename != '']
    
    if len(files) == 0:
        return jsonify({'success': False, 'error': 'No files selected'})
    
    # Aggregated stats across all files
    total_new_transactions = 0
    total_duplicates = 0
    total_swept = 0
    total_rules_updated = 0
    all_new_transactions = []
    files_processed = []
    errors = []
    
    for file in files:
        if not allowed_file(file.filename):
            errors.append(f'{file.filename}: Invalid file type')
            continue
        
        # Save file
        filename = secure_filename(file.filename)
        filepath = Config.UPLOAD_FOLDER / filename
        file.save(str(filepath))
        
        try:
            # Auto-detect CSV type from columns
            csv_type, confidence, has_categories = CSVDetector.detect(str(filepath))
            format_info = CSVDetector.get_format_info(csv_type)
            
            if csv_type == CSVType.UNKNOWN:
                errors.append(f'{file.filename}: Could not detect CSV format')
                continue
            
            # Determine whether to use CSV categories or apply auto-tagging
            use_csv_categories = (category_source == 'csv')
            
            # If CSV doesn't have categories but user chose CSV categories, use rules instead
            if use_csv_categories and not has_categories:
                use_csv_categories = False
            
            # Parse based on detected type
            if csv_type == CSVType.CHASE_CREDIT or csv_type == CSVType.CHASE_DEBIT:
                transactions = ChaseParser.parse(str(filepath), use_csv_categories=use_csv_categories)
            else:  # DISCOVER
                transactions = DiscoverParser.parse(str(filepath), use_csv_categories=use_csv_categories)
            
            # Filter out duplicate transactions
            unique_transactions, duplicate_count = filter_duplicates(
                transactions, 
                all_transactions + all_new_transactions
            )
            total_duplicates += duplicate_count
            
            # Apply sweep/exclusion rules
            unique_transactions, swept_count = exclusion_engine.filter_new_transactions(unique_transactions)
            total_swept += swept_count
            
            # Apply category rules
            rules_updated = rule_engine.apply_to_all(unique_transactions)
            total_rules_updated += rules_updated
            
            # Collect for batch processing
            all_new_transactions.extend(unique_transactions)
            total_new_transactions += len(unique_transactions)
            
            files_processed.append({
                'filename': file.filename,
                'format': format_info['name'],
                'count': len(unique_transactions)
            })
            
        except Exception as e:
            errors.append(f'{file.filename}: {str(e)}')
            continue
    
    # Add all new transactions to global storage
    all_transactions.extend(all_new_transactions)
    
    # Sync to Google Sheets
    sheets_synced = False
    sheets_error = None
    if len(all_new_transactions) > 0:
        try:
            sheets_client = SheetsClient()
            if sheets_client.is_connected():
                sync_result = sheets_client.sync_transactions(all_new_transactions)
                sheets_client.create_monthly_summary(all_transactions)
                
                if 'error' in sync_result:
                    sheets_error = sync_result['error']
                else:
                    sheets_synced = True
        except Exception as e:
            sheets_error = str(e)
    
    return jsonify({
        'success': total_new_transactions > 0 or total_duplicates > 0,
        'new_count': total_new_transactions,
        'duplicate_count': total_duplicates,
        'swept_count': total_swept,
        'rules_applied': total_rules_updated,
        'files_processed': files_processed,
        'errors': errors,
        'sheets_synced': sheets_synced,
        'sheets_error': sheets_error
    })


@app.route('/api/sheets-status')
def api_sheets_status():
    """Check if Google Sheets is configured and has data."""
    try:
        sheets_client = SheetsClient()
        
        if not sheets_client.is_connected():
            return jsonify({
                'connected': False,
                'error': sheets_client.last_error
            })
        
        # Try to check if there's data
        try:
            worksheet = sheets_client.spreadsheet.worksheet('All Transactions')
            row_count = worksheet.row_count
            # Get actual data count (subtract header)
            all_values = worksheet.get_all_values()
            data_count = len(all_values) - 1 if len(all_values) > 0 else 0
            
            return jsonify({
                'connected': True,
                'has_data': data_count > 0,
                'data_count': data_count
            })
        except:
            return jsonify({
                'connected': True,
                'has_data': False,
                'data_count': 0
            })
            
    except Exception as e:
        return jsonify({
            'connected': False,
            'error': str(e)
        })


@app.route('/')
def index():
    """Home page with interactive dashboard."""
    # If no transactions in memory, check if we should load from Google Sheets
    if len(all_transactions) == 0:
        # Check if Google Sheets is configured
        if not needs_setup():
            # Setup is complete, check if we should redirect to loading page
            # Only redirect to loading if not coming from there (prevent loop)
            if request.args.get('loaded') != 'true':
                return redirect(url_for('loading'))
        
        # No setup or explicitly came from loading with no data - show upload page
        return redirect(url_for('upload'))
    
    expense_transactions = [t for t in all_transactions if t.is_expense]
    
    # Get analytics data for the interactive dashboard
    categories = TransactionCategorizer.categorize_by_spending(expense_transactions)
    monthly_trends = TransactionCategorizer.monthly_trends(all_transactions)
    weekly_spending = TransactionCategorizer.weekly_spending(all_transactions)
    daily_spending = TransactionCategorizer.daily_spending(all_transactions, days=30)
    day_of_week = TransactionCategorizer.day_of_week_analysis(all_transactions)
    spending_by_bank = TransactionCategorizer.spending_by_bank(all_transactions)
    statistics = TransactionCategorizer.get_statistics(all_transactions)
    
    # Enhanced classification data
    budget_health = ExpenseClassifier.get_budget_health(all_transactions)
    classification = ExpenseClassifier.analyze_by_dimension(all_transactions)
    
    # Calculate totals
    total_spent = sum(abs(t.amount) for t in all_transactions if t.is_expense)
    total_income = sum(t.amount for t in all_transactions if t.is_income)
    
    return render_template('index.html',
                         categories=categories,
                         monthly_trends=monthly_trends,
                         weekly_spending=weekly_spending,
                         daily_spending=daily_spending,
                         day_of_week=day_of_week,
                         spending_by_bank=spending_by_bank,
                         statistics=statistics,
                         total_spent=total_spent,
                         total_income=total_income,
                         category_colors=TransactionCategorizer.CATEGORY_COLORS,
                         budget_health=budget_health,
                         classification=classification)

@app.route('/upload', methods=['GET', 'POST'])
def upload():
    """Upload CSV file page. Supports multiple file uploads."""
    if request.method == 'POST':
        # Check if files were uploaded
        if 'files' not in request.files:
            flash('No file selected', 'error')
            return redirect(request.url)
        
        files = request.files.getlist('files')
        category_source = request.form.get('category_source', 'csv')  # 'csv' or 'rules'
        
        # Filter out empty file inputs
        files = [f for f in files if f.filename != '']
        
        if len(files) == 0:
            flash('No file selected', 'error')
            return redirect(request.url)
        
        # Aggregated stats across all files
        total_new_transactions = 0
        total_duplicates = 0
        total_swept = 0
        total_rules_updated = 0
        all_new_transactions = []  # Collect all new transactions for batch sync
        files_processed = []
        
        for file in files:
            if not allowed_file(file.filename):
                flash(f'Skipped {file.filename}: Invalid file type. Only CSV files are allowed.', 'warning')
                continue
            
            # Save file
            filename = secure_filename(file.filename)
            filepath = Config.UPLOAD_FOLDER / filename
            file.save(str(filepath))
            
            try:
                # Auto-detect CSV type from columns
                csv_type, confidence, has_categories = CSVDetector.detect(str(filepath))
                format_info = CSVDetector.get_format_info(csv_type)
                
                if csv_type == CSVType.UNKNOWN:
                    flash(f'Skipped {file.filename}: Could not detect CSV format.', 'warning')
                    continue
                
                # Determine whether to use CSV categories or apply auto-tagging
                use_csv_categories = (category_source == 'csv')
                
                # If CSV doesn't have categories but user chose CSV categories, use rules instead
                if use_csv_categories and not has_categories:
                    use_csv_categories = False
                
                # Parse based on detected type
                if csv_type == CSVType.CHASE_CREDIT or csv_type == CSVType.CHASE_DEBIT:
                    transactions = ChaseParser.parse(str(filepath), use_csv_categories=use_csv_categories)
                else:  # DISCOVER
                    transactions = DiscoverParser.parse(str(filepath), use_csv_categories=use_csv_categories)
                
                # Filter out duplicate transactions (check against existing + already added in this batch)
                unique_transactions, duplicate_count = filter_duplicates(
                    transactions, 
                    all_transactions + all_new_transactions
                )
                total_duplicates += duplicate_count
                
                # Apply sweep/exclusion rules to filter out unwanted transactions
                unique_transactions, swept_count = exclusion_engine.filter_new_transactions(unique_transactions)
                total_swept += swept_count
                
                # Apply category rules to new transactions
                rules_updated = rule_engine.apply_to_all(unique_transactions)
                total_rules_updated += rules_updated
                
                # Collect for batch processing
                all_new_transactions.extend(unique_transactions)
                total_new_transactions += len(unique_transactions)
                
                files_processed.append({
                    'filename': file.filename,
                    'format': format_info['name'],
                    'count': len(unique_transactions)
                })
                
            except Exception as e:
                flash(f'Error parsing {file.filename}: {str(e)}', 'error')
                continue
        
        # Add all new transactions to global storage
        all_transactions.extend(all_new_transactions)
        
        # Show summary of processed files
        if len(files_processed) > 0:
            file_summary = ', '.join([f"{f['format']}" for f in files_processed])
            flash(f'Processed {len(files_processed)} file(s): {file_summary}', 'info')
        
        if total_duplicates > 0:
            flash(f'Skipped {total_duplicates} duplicate transaction(s) across all files.', 'info')
        
        if total_swept > 0:
            flash(f'Swept {total_swept} transaction(s) based on your sweep rules.', 'info')
        
        if category_source == 'csv':
            flash(f'Using categories from CSV files. {total_rules_updated} transaction(s) updated by custom rules.', 'info')
        else:
            flash(f'Applied auto-tagging rules. {total_rules_updated} transaction(s) matched custom rules.', 'info')
        
        # Sync to Google Sheets (batch sync all new transactions at once)
        if len(all_new_transactions) > 0:
            try:
                sheets_client = SheetsClient()
                if sheets_client.is_connected():
                    sync_result = sheets_client.sync_transactions(all_new_transactions)
                    sheets_client.create_monthly_summary(all_transactions)
                    
                    if 'error' in sync_result:
                        flash(f'Warning: {sync_result["error"]}', 'warning')
                    else:
                        flash(f'Synced {sync_result["synced_count"]} transactions to Google Sheets!', 'success')
                else:
                    flash('Warning: Google Sheets not configured. Transactions saved locally only.', 'warning')
            except Exception as e:
                flash(f'Warning: Could not sync to Google Sheets: {str(e)}', 'warning')
        
        if total_new_transactions > 0:
            flash(f'Successfully uploaded {total_new_transactions} new transaction(s)!', 'success')
            return redirect(url_for('index'))
        elif total_duplicates > 0:
            flash(f'All transactions were already in the system.', 'info')
            return redirect(url_for('index'))
        else:
            flash('No valid CSV files were processed.', 'warning')
            return redirect(request.url)
    
    return render_template('upload.html')

@app.route('/api/transactions')
def api_transactions():
    """API endpoint to get all transactions."""
    transactions_data = [t.to_dict() for t in all_transactions]
    return jsonify(transactions_data)

@app.route('/api/insights')
def api_insights():
    """API endpoint to get insights."""
    insights = InsightsGenerator.generate_insights(all_transactions)
    return jsonify(insights)

@app.route('/api/categories')
def api_categories():
    """API endpoint to get category breakdown."""
    expense_transactions = [t for t in all_transactions if t.is_expense]
    categories = TransactionCategorizer.categorize_by_spending(expense_transactions)
    return jsonify(categories)

@app.route('/api/trends')
def api_trends():
    """API endpoint to get monthly trends."""
    trends = TransactionCategorizer.monthly_trends(all_transactions)
    return jsonify(trends)

@app.route('/api/weekly-spending')
def api_weekly_spending():
    """API endpoint for weekly spending data."""
    data = TransactionCategorizer.weekly_spending(all_transactions)
    return jsonify(data)

@app.route('/api/daily-spending')
def api_daily_spending():
    """API endpoint for daily spending data."""
    days = request.args.get('days', 30, type=int)
    data = TransactionCategorizer.daily_spending(all_transactions, days=days)
    return jsonify(data)

@app.route('/api/day-of-week')
def api_day_of_week():
    """API endpoint for day of week analysis."""
    data = TransactionCategorizer.day_of_week_analysis(all_transactions)
    return jsonify(data)

@app.route('/api/spending-by-bank')
def api_spending_by_bank():
    """API endpoint for spending by bank."""
    data = TransactionCategorizer.spending_by_bank(all_transactions)
    return jsonify(data)

@app.route('/api/velocity')
def api_velocity():
    """API endpoint for spending velocity metrics."""
    data = TransactionCategorizer.spending_velocity(all_transactions)
    return jsonify(data)

@app.route('/api/category-trends')
def api_category_trends():
    """API endpoint for category trends over time."""
    data = TransactionCategorizer.category_trends(all_transactions)
    return jsonify(data)

@app.route('/api/statistics')
def api_statistics():
    """API endpoint for statistical metrics."""
    data = TransactionCategorizer.get_statistics(all_transactions)
    return jsonify(data)

@app.route('/api/chart-data')
def api_chart_data():
    """Combined API endpoint for all chart data."""
    expense_transactions = [t for t in all_transactions if t.is_expense]
    categories = TransactionCategorizer.categorize_by_spending(expense_transactions)
    
    return jsonify({
        'categories': categories,
        'monthly_trends': TransactionCategorizer.monthly_trends(all_transactions),
        'weekly_spending': TransactionCategorizer.weekly_spending(all_transactions),
        'day_of_week': TransactionCategorizer.day_of_week_analysis(all_transactions),
        'spending_by_bank': TransactionCategorizer.spending_by_bank(all_transactions),
        'velocity': TransactionCategorizer.spending_velocity(all_transactions),
        'statistics': TransactionCategorizer.get_statistics(all_transactions),
        'category_colors': TransactionCategorizer.CATEGORY_COLORS
    })


# =========================================================================
# ENHANCED CLASSIFICATION API ENDPOINTS
# =========================================================================

@app.route('/api/classification')
def api_classification():
    """API endpoint for multi-dimensional expense classification analysis."""
    analysis = ExpenseClassifier.analyze_by_dimension(all_transactions)
    return jsonify(analysis)

@app.route('/api/budget-health')
def api_budget_health():
    """API endpoint for 50/30/20 budget health analysis."""
    health = ExpenseClassifier.get_budget_health(all_transactions)
    return jsonify(health)

@app.route('/api/subscriptions')
def api_subscriptions():
    """API endpoint for subscription analysis."""
    subscriptions = ExpenseClassifier.get_subscription_summary(all_transactions)
    return jsonify(subscriptions)

@app.route('/api/reduction-opportunities')
def api_reduction_opportunities():
    """API endpoint for spending reduction opportunities."""
    opportunities = ExpenseClassifier.get_reduction_opportunities(all_transactions)
    return jsonify(opportunities)

@app.route('/api/necessity')
def api_necessity():
    """API endpoint for needs vs wants vs savings breakdown."""
    analysis = ExpenseClassifier.analyze_by_dimension(all_transactions)
    return jsonify(analysis.get('by_necessity', {}))

@app.route('/api/transactions/filter')
def api_transactions_filter():
    """API endpoint for filtered transactions by date range, category, period, necessity, and recurrence.
    
    Supports multiple simultaneous filters - all filters are applied with AND logic.
    Also supports untagged filters to find transactions missing specific tags.
    """
    from datetime import datetime, timedelta
    
    # Get filter parameters
    start_date = request.args.get('start_date')
    end_date = request.args.get('end_date')
    category = request.args.get('category')
    categories = request.args.getlist('categories')  # Support multiple categories
    necessity = request.args.get('necessity')
    necessities = request.args.getlist('necessities')  # Support multiple necessities
    recurrence = request.args.get('recurrence')
    recurrences = request.args.getlist('recurrences')  # Support multiple recurrences
    period_type = request.args.get('period_type')  # 'day', 'week', 'month', 'year'
    period_value = request.args.get('period_value')  # e.g., '2024-01', 'Monday', '2024-W01'
    
    # Untagged filter parameters
    untagged_category = request.args.get('untagged_category') == 'true'
    untagged_necessity = request.args.get('untagged_necessity') == 'true'
    untagged_recurrence = request.args.get('untagged_recurrence') == 'true'
    
    filtered = all_transactions.copy()
    
    # Filter by date range
    if start_date:
        try:
            start = datetime.strptime(start_date, '%Y-%m-%d').date()
            filtered = [t for t in filtered if t.transaction_date.date() >= start]
        except ValueError:
            pass
    
    if end_date:
        try:
            end = datetime.strptime(end_date, '%Y-%m-%d').date()
            filtered = [t for t in filtered if t.transaction_date.date() <= end]
        except ValueError:
            pass
    
    # Filter by category (single or multiple)
    if category:
        filtered = [t for t in filtered if t.category == category]
    elif categories:
        filtered = [t for t in filtered if t.category in categories]
    
    # Filter by necessity (single or multiple)
    if necessity:
        filtered = [t for t in filtered if getattr(t, 'necessity', 'Unknown') == necessity]
    elif necessities:
        filtered = [t for t in filtered if getattr(t, 'necessity', 'Unknown') in necessities]
    
    # Filter by recurrence (single or multiple)
    if recurrence:
        filtered = [t for t in filtered if getattr(t, 'recurrence', 'One-time') == recurrence]
    elif recurrences:
        filtered = [t for t in filtered if getattr(t, 'recurrence', 'One-time') in recurrences]
    
    # Filter by period type
    if period_type and period_value:
        if period_type == 'month':
            # period_value format: 'YYYY-MM'
            filtered = [t for t in filtered if t.month_year == period_value]
        elif period_type == 'week':
            # period_value format: 'YYYY-MM-DD' (week start date)
            try:
                week_start = datetime.strptime(period_value, '%Y-%m-%d').date()
                week_end = week_start + timedelta(days=6)
                filtered = [t for t in filtered if week_start <= t.transaction_date.date() <= week_end]
            except ValueError:
                pass
        elif period_type == 'day':
            # period_value format: 'YYYY-MM-DD'
            try:
                day = datetime.strptime(period_value, '%Y-%m-%d').date()
                filtered = [t for t in filtered if t.transaction_date.date() == day]
            except ValueError:
                pass
        elif period_type == 'day_of_week':
            # period_value: 'Monday', 'Tuesday', etc.
            days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
            if period_value in days:
                day_index = days.index(period_value)
                filtered = [t for t in filtered if t.transaction_date.weekday() == day_index]
        elif period_type == 'year':
            # period_value format: 'YYYY'
            try:
                year = int(period_value)
                filtered = [t for t in filtered if t.transaction_date.year == year]
            except ValueError:
                pass
    
    # Filter for untagged transactions
    # Categories that indicate "untagged" or generic categorization
    untagged_categories = {'Other', 'Uncategorized', 'Unknown', ''}
    
    if untagged_category:
        # Filter for transactions with generic/untagged category
        filtered = [t for t in filtered if t.category in untagged_categories]
    
    if untagged_necessity:
        # Filter for transactions with Unknown necessity, excluding Income category
        # (Income transactions don't have necessity by design)
        filtered = [t for t in filtered if 
                    getattr(t, 'necessity', 'Unknown') == 'Unknown' and 
                    t.category.lower() != 'income']
    
    if untagged_recurrence:
        # Filter for transactions with Unknown recurrence
        filtered = [t for t in filtered if getattr(t, 'recurrence', 'Unknown') == 'Unknown']
    
    # Sort by date descending
    filtered.sort(key=lambda t: t.transaction_date, reverse=True)
    
    # Calculate summary
    expenses = [t for t in filtered if t.is_expense]
    income = [t for t in filtered if t.is_income]
    
    return jsonify({
        'transactions': [t.to_dict() for t in filtered],
        'summary': {
            'count': len(filtered),
            'total_spent': round(sum(abs(t.amount) for t in expenses), 2),
            'total_income': round(sum(t.amount for t in income), 2),
            'expense_count': len(expenses),
            'income_count': len(income)
        }
    })


# =========================================================================
# CATEGORY RULES API ENDPOINTS
# =========================================================================

@app.route('/api/category-rules', methods=['GET'])
def api_get_category_rules():
    """Get all category rules."""
    rules = rule_engine.get_all_rules()
    return jsonify({
        'rules': [r.to_dict() for r in rules]
    })

@app.route('/api/category-rules', methods=['POST'])
def api_create_category_rule():
    """Create a new category rule with support for multiple tags."""
    data = request.get_json()
    
    if not data:
        return jsonify({'error': 'No data provided'}), 400
    
    keywords = data.get('keywords', [])
    priority = data.get('priority', 0)
    
    # Support new multi-tag format
    tags = data.get('tags', {})
    
    # For backward compatibility, also accept legacy format
    category = data.get('category', '').strip() if isinstance(data.get('category'), str) else ''
    field = data.get('field', 'category').strip() if isinstance(data.get('field'), str) else 'category'
    
    # Validate tags
    allowed_fields = ['category', 'necessity', 'recurrence']
    
    # Build tags dict from input
    if isinstance(tags, dict) and tags:
        # Filter to only allowed fields with non-empty values
        tags = {k.strip(): v.strip() for k, v in tags.items() if k.strip() in allowed_fields and v and v.strip()}
    elif category:
        # Legacy format: single field/category
        if field not in allowed_fields:
            field = 'category'
        tags = {field: category}
    else:
        return jsonify({'error': 'At least one tag (category, necessity, or recurrence) is required'}), 400
    
    if not tags:
        return jsonify({'error': 'At least one tag with a non-empty value is required'}), 400
    
    if not keywords or not isinstance(keywords, list) or len(keywords) == 0:
        return jsonify({'error': 'At least one keyword is required'}), 400
    
    # Clean up keywords
    keywords = [k.strip() for k in keywords if k.strip()]
    
    if len(keywords) == 0:
        return jsonify({'error': 'At least one non-empty keyword is required'}), 400
    
    # For backward compatibility, set category to first tag value
    first_field = list(tags.keys())[0]
    first_value = tags[first_field]
    
    # Create the rule with tags
    rule = rule_engine.add_rule(first_value, keywords, priority, first_field, tags)
    
    # Apply rule to all existing transactions
    updated_count = rule_engine.apply_single_rule(rule, all_transactions)
    
    return jsonify({
        'success': True,
        'rule': rule.to_dict(),
        'transactions_updated': updated_count
    })

@app.route('/api/category-rules/<rule_id>', methods=['PUT'])
def api_update_category_rule(rule_id):
    """Update an existing category rule."""
    data = request.get_json()
    
    if not data:
        return jsonify({'error': 'No data provided'}), 400
    
    category = data.get('category')
    keywords = data.get('keywords')
    priority = data.get('priority')
    enabled = data.get('enabled')
    
    # Clean up keywords if provided
    if keywords is not None:
        keywords = [k.strip() for k in keywords if k.strip()]
        if len(keywords) == 0:
            return jsonify({'error': 'At least one non-empty keyword is required'}), 400
    
    rule = rule_engine.update_rule(rule_id, category, keywords, priority, enabled)
    
    if not rule:
        return jsonify({'error': 'Rule not found'}), 404
    
    # Re-apply all rules to all transactions
    rule_engine.apply_to_all(all_transactions)
    
    return jsonify({
        'success': True,
        'rule': rule.to_dict()
    })

@app.route('/api/category-rules/<rule_id>', methods=['DELETE'])
def api_delete_category_rule(rule_id):
    """Delete a category rule."""
    success = rule_engine.delete_rule(rule_id)
    
    if not success:
        return jsonify({'error': 'Rule not found'}), 404
    
    return jsonify({'success': True})

@app.route('/api/category-rules/apply-all', methods=['POST'])
def api_apply_all_rules():
    """Re-apply all category rules to all transactions."""
    updated_count = rule_engine.apply_to_all(all_transactions)
    return jsonify({
        'success': True,
        'transactions_updated': updated_count
    })

@app.route('/api/category-rules/preview', methods=['POST'])
def api_preview_rule():
    """Preview how many transactions a rule would match."""
    data = request.get_json()
    
    if not data:
        return jsonify({'error': 'No data provided'}), 400
    
    keywords = data.get('keywords', [])
    
    if not keywords or not isinstance(keywords, list):
        return jsonify({'matching_count': 0, 'matches': []})
    
    # Clean up keywords
    keywords = [k.strip().lower() for k in keywords if k.strip()]
    
    if len(keywords) == 0:
        return jsonify({'matching_count': 0, 'matches': []})
    
    # Find matching transactions
    matches = []
    for t in all_transactions:
        desc_lower = t.description.lower()
        if all(kw in desc_lower for kw in keywords):
            matches.append({
                'description': t.description,
                'current_category': t.category,
                'amount': t.amount,
                'date': t.transaction_date.strftime('%Y-%m-%d')
            })
    
    return jsonify({
        'matching_count': len(matches),
        'matches': matches  # Return all matches for preview
    })


# =========================================================================
# SWEEP/EXCLUSION RULES API ENDPOINTS
# =========================================================================

@app.route('/api/sweep-rules', methods=['GET'])
def api_get_sweep_rules():
    """Get all sweep/exclusion rules."""
    rules = exclusion_engine.get_all_rules()
    return jsonify({
        'rules': [r.to_dict() for r in rules]
    })

@app.route('/api/sweep-rules', methods=['POST'])
def api_create_sweep_rule():
    """Create a new sweep rule and apply it to existing transactions."""
    global all_transactions
    
    data = request.get_json()
    
    if not data:
        return jsonify({'error': 'No data provided'}), 400
    
    keywords = data.get('keywords', [])
    title = data.get('title', '').strip()
    
    if not keywords or not isinstance(keywords, list) or len(keywords) == 0:
        return jsonify({'error': 'At least one keyword is required'}), 400
    
    # Clean up keywords
    keywords = [k.strip() for k in keywords if k.strip()]
    
    if len(keywords) == 0:
        return jsonify({'error': 'At least one valid keyword is required'}), 400
    
    # Create the rule with title
    rule = exclusion_engine.add_rule(keywords, title=title)
    
    # Apply to existing transactions (sweep them away)
    all_transactions, swept_count = exclusion_engine.sweep_transactions(all_transactions)
    
    return jsonify({
        'success': True,
        'rule': rule.to_dict(),
        'swept_count': swept_count
    })

# IMPORTANT: Static path routes must come BEFORE dynamic <rule_id> routes
# Otherwise Flask will match "join", "preview", "apply-all" as rule_id values

@app.route('/api/sweep-rules/join', methods=['POST'])
def api_join_sweep_rules():
    """
    Join multiple sweep rules into a single rule using OR logic.
    
    Each original rule uses AND logic for its keywords.
    The joined rule matches if ANY of the original rules would match.
    """
    data = request.get_json()
    
    if not data:
        return jsonify({'error': 'No data provided'}), 400
    
    rule_ids = data.get('rule_ids', [])
    title = data.get('title', '').strip()
    
    if not rule_ids or len(rule_ids) < 2:
        return jsonify({'error': 'At least 2 rules are required to join'}), 400
    
    joined_rule = exclusion_engine.join_rules(rule_ids, title)
    
    if not joined_rule:
        return jsonify({'error': 'Could not join rules. Make sure the rules exist and are enabled.'}), 400
    
    return jsonify({
        'success': True,
        'rule': joined_rule.to_dict(),
        'joined_count': len(rule_ids)
    })

@app.route('/api/sweep-rules/preview', methods=['POST'])
def api_preview_sweep_rule():
    """Preview how many transactions a sweep rule would match."""
    data = request.get_json()
    
    if not data:
        return jsonify({'error': 'No data provided'}), 400
    
    keywords = data.get('keywords', [])
    
    if not keywords or not isinstance(keywords, list):
        return jsonify({'match_count': 0, 'sample_matches': []})
    
    # Clean up keywords
    keywords = [k.strip().lower() for k in keywords if k.strip()]
    
    if len(keywords) == 0:
        return jsonify({'match_count': 0, 'sample_matches': []})
    
    count, matches = exclusion_engine.count_matches(keywords, all_transactions)
    
    return jsonify({
        'match_count': count,
        'sample_matches': matches[:20]
    })

@app.route('/api/sweep-rules/apply-all', methods=['POST'])
def api_apply_all_sweep_rules():
    """Re-apply all sweep rules to all transactions."""
    global all_transactions
    
    all_transactions, swept_count = exclusion_engine.sweep_transactions(all_transactions)
    
    return jsonify({
        'success': True,
        'swept_count': swept_count
    })

# Dynamic <rule_id> routes must come AFTER static path routes
@app.route('/api/sweep-rules/<rule_id>', methods=['PUT'])
def api_update_sweep_rule(rule_id):
    """Update an existing sweep rule."""
    data = request.get_json()
    
    if not data:
        return jsonify({'error': 'No data provided'}), 400
    
    keywords = data.get('keywords')
    enabled = data.get('enabled')
    
    rule = exclusion_engine.update_rule(
        rule_id,
        keywords=keywords,
        enabled=enabled
    )
    
    if not rule:
        return jsonify({'error': 'Rule not found'}), 404
    
    return jsonify({
        'success': True,
        'rule': rule.to_dict()
    })

@app.route('/api/sweep-rules/<rule_id>', methods=['DELETE'])
def api_delete_sweep_rule(rule_id):
    """Delete a sweep rule."""
    success = exclusion_engine.delete_rule(rule_id)
    
    if not success:
        return jsonify({'error': 'Rule not found'}), 404
    
    return jsonify({'success': True})


# =========================================================================
# RULES EXPORT/IMPORT API ENDPOINTS
# =========================================================================

@app.route('/api/rules/export', methods=['GET'])
def api_export_rules():
    """Export all auto-tag rules and sweep rules as JSON."""
    try:
        category_rules = rule_engine.get_all_rules()
        sweep_rules = exclusion_engine.get_all_rules()
        
        export_data = {
            'version': '1.0',
            'exported_at': __import__('datetime').datetime.now().isoformat(),
            'auto_tag_rules': [r.to_dict() for r in category_rules],
            'sweep_rules': [r.to_dict() for r in sweep_rules]
        }
        
        return jsonify(export_data)
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/rules/import', methods=['POST'])
def api_import_rules():
    """Import auto-tag rules and sweep rules from JSON."""
    try:
        data = request.get_json()
        
        if not data:
            return jsonify({'error': 'No data provided'}), 400
        
        imported_tag_rules = 0
        imported_sweep_rules = 0
        skipped_duplicates = 0
        
        # Import auto-tag rules
        auto_tag_rules = data.get('auto_tag_rules', [])
        existing_tag_keywords = {tuple(sorted(r.keywords)) for r in rule_engine.get_all_rules()}
        
        for rule_data in auto_tag_rules:
            # Check for duplicate by keywords
            rule_keywords = tuple(sorted(rule_data.get('keywords', [])))
            if rule_keywords in existing_tag_keywords:
                skipped_duplicates += 1
                continue
            
            # Create new rule without ID (will be auto-generated)
            tags = rule_data.get('tags', {})
            if not tags and 'category' in rule_data:
                tags = {rule_data.get('field', 'category'): rule_data.get('category', '')}
            
            if tags and rule_data.get('keywords'):
                first_field = list(tags.keys())[0]
                first_value = tags[first_field]
                rule_engine.add_rule(
                    category=first_value,
                    keywords=rule_data.get('keywords', []),
                    priority=rule_data.get('priority', 0),
                    field=first_field,
                    tags=tags
                )
                existing_tag_keywords.add(rule_keywords)
                imported_tag_rules += 1
        
        # Import sweep rules
        sweep_rules = data.get('sweep_rules', [])
        existing_sweep_keywords = {tuple(sorted(r.keywords)) for r in exclusion_engine.get_all_rules()}
        
        for rule_data in sweep_rules:
            # Check for duplicate by keywords
            rule_keywords = tuple(sorted(rule_data.get('keywords', [])))
            if rule_keywords in existing_sweep_keywords:
                skipped_duplicates += 1
                continue
            
            if rule_data.get('keywords'):
                exclusion_engine.add_rule(
                    keywords=rule_data.get('keywords', []),
                    title=rule_data.get('title', '')
                )
                existing_sweep_keywords.add(rule_keywords)
                imported_sweep_rules += 1
        
        return jsonify({
            'success': True,
            'imported_auto_tag_rules': imported_tag_rules,
            'imported_sweep_rules': imported_sweep_rules,
            'skipped_duplicates': skipped_duplicates
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 500


# =========================================================================
# TRANSACTION CATEGORY UPDATE ENDPOINT
# =========================================================================

@app.route('/api/transactions/update-category', methods=['POST'])
def api_update_transaction_category():
    """Update the category of a specific transaction."""
    data = request.get_json()
    
    if not data:
        return jsonify({'error': 'No data provided'}), 400
    
    description = data.get('description')
    date = data.get('date')
    new_category = data.get('category', '').strip()
    
    if not description or not date:
        return jsonify({'error': 'Transaction description and date are required'}), 400
    
    if not new_category:
        return jsonify({'error': 'New category is required'}), 400
    
    # Find and update the transaction
    updated = False
    for t in all_transactions:
        if t.description == description and t.transaction_date.strftime('%Y-%m-%d') == date:
            t.category = new_category
            updated = True
            break
    
    if not updated:
        return jsonify({'error': 'Transaction not found'}), 404
    
    return jsonify({'success': True, 'new_category': new_category})


@app.route('/api/transactions/update-field', methods=['POST'])
def api_update_transaction_field():
    """Update any field of a specific transaction."""
    data = request.get_json()
    
    if not data:
        return jsonify({'error': 'No data provided'}), 400
    
    description = data.get('description')
    date = data.get('date')
    field = data.get('field', '').strip()
    value = data.get('value', '').strip()
    
    if not description or not date:
        return jsonify({'error': 'Transaction description and date are required'}), 400
    
    if not field:
        return jsonify({'error': 'Field name is required'}), 400
    
    # Allowed fields to update
    allowed_fields = ['category', 'necessity', 'recurrence', 'note']
    
    if field not in allowed_fields:
        return jsonify({'error': f'Field "{field}" is not editable'}), 400
    
    # Find and update the transaction
    updated = False
    updated_fields = {field: value}
    
    for t in all_transactions:
        if t.description == description and t.transaction_date.strftime('%Y-%m-%d') == date:
            setattr(t, field, value)
            
            # Special handling for Income category: clear necessity since Income isn't Needs/Wants/Savings
            if field == 'category' and value == 'Income':
                t.necessity = 'Unknown'
                updated_fields['necessity'] = 'Unknown'
            
            updated = True
            break
    
    if not updated:
        return jsonify({'error': 'Transaction not found'}), 404
    
    return jsonify({'success': True, 'field': field, 'value': value, 'updated_fields': updated_fields})


@app.route('/api/transactions/add-cash', methods=['POST'])
def api_add_cash_transaction():
    """Add a manual cash transaction.
    
    This allows users to add transactions that weren't in their bank CSV exports,
    such as cash purchases. The transaction is added to memory and synced to Google Sheets.
    """
    from backend.models.transaction import Transaction
    from datetime import datetime
    
    data = request.get_json()
    
    if not data:
        return jsonify({'error': 'No data provided'}), 400
    
    # Required fields
    date_str = data.get('date', '').strip()
    amount = data.get('amount')
    description = data.get('description', '').strip()
    
    if not date_str or amount is None or not description:
        return jsonify({'error': 'Date, amount, and description are required'}), 400
    
    try:
        amount = float(amount)
    except (ValueError, TypeError):
        return jsonify({'error': 'Invalid amount'}), 400
    
    # Parse date
    try:
        transaction_date = datetime.strptime(date_str, '%Y-%m-%d')
    except ValueError:
        return jsonify({'error': 'Invalid date format. Use YYYY-MM-DD'}), 400
    
    # Optional fields
    category = data.get('category', 'Other').strip() or 'Other'
    bank = data.get('bank', 'Cash').strip() or 'Cash'
    necessity = data.get('necessity', 'Unknown').strip() or 'Unknown'
    recurrence = data.get('recurrence', 'One-time').strip() or 'One-time'
    note = data.get('note', '').strip()
    
    # Create the transaction object
    transaction = Transaction(
        transaction_date=transaction_date,
        post_date=transaction_date,  # Same as transaction date for cash
        description=description,
        amount=amount,
        category=category,
        bank=bank
    )
    
    # Set additional fields
    transaction.necessity = necessity
    transaction.recurrence = recurrence
    transaction.note = note
    
    # Add to global transactions list
    all_transactions.append(transaction)
    
    # Sync to Google Sheets
    sheets_synced = False
    sheets_error = None
    try:
        sheets_client = SheetsClient()
        if sheets_client.is_connected():
            sync_result = sheets_client.sync_transactions([transaction])
            if 'error' in sync_result:
                sheets_error = sync_result['error']
            else:
                sheets_synced = True
    except Exception as e:
        sheets_error = str(e)
    
    return jsonify({
        'success': True,
        'transaction': transaction.to_dict(),
        'sheets_synced': sheets_synced,
        'sheets_error': sheets_error
    })


# =========================================================================
# GOOGLE SHEETS SYNC ENDPOINT
# =========================================================================

@app.route('/api/sync-to-sheets', methods=['POST'])
def api_sync_to_sheets():
    """Manually sync all transactions to Google Sheets."""
    if len(all_transactions) == 0:
        return jsonify({'success': False, 'error': 'No transactions to sync'})
    
    try:
        sheets_client = SheetsClient()
        
        if not sheets_client.is_connected():
            return jsonify({
                'success': False, 
                'error': 'Google Sheets not configured. Please complete setup first.'
            })
        
        # Clear and re-sync all transactions
        sync_result = sheets_client.sync_transactions(all_transactions, clear_first=True)
        
        # Also update the monthly summary
        sheets_client.create_monthly_summary(all_transactions)
        
        # Sync period notes (weekly/monthly analysis) to Google Sheets
        all_notes = period_notes_engine.get_all_notes()
        notes_result = sheets_client.sync_period_notes(all_notes)
        notes_synced = notes_result.get('synced_count', 0) if notes_result.get('success') else 0
        
        if 'error' in sync_result:
            return jsonify({'success': False, 'error': sync_result['error']})
        
        return jsonify({
            'success': True,
            'synced_count': sync_result.get('synced_count', len(all_transactions)),
            'notes_synced': notes_synced,
            'message': f'Successfully synced {sync_result.get("synced_count", len(all_transactions))} transactions and {notes_synced} period notes to Google Sheets'
        })
        
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})


@app.route('/api/apply-rules-to-sheets', methods=['POST'])
def api_apply_rules_to_sheets():
    """
    Load ALL transactions from Google Sheets, apply all auto-tag rules,
    and sync the updated transactions back to Google Sheets.
    """
    try:
        from backend.sheets.sheets_client import SheetsClient as LocalSheetsClient
        sheets_client = LocalSheetsClient()
        
        if not sheets_client.is_connected():
            return jsonify({
                'success': False,
                'error': sheets_client.last_error or 'Google Sheets not configured. Please complete setup first.'
            })
        
        # Load ALL transactions from Google Sheets (no date filter)
        result = sheets_client.load_transactions(start_date=None)
        
        if 'error' in result and result['error']:
            return jsonify({'success': False, 'error': result['error']})
        
        sheet_transactions = result.get('transactions', [])
        
        if len(sheet_transactions) == 0:
            return jsonify({
                'success': False,
                'error': 'No transactions found in Google Sheets'
            })
        
        # Apply all category rules to the loaded transactions
        updated_count = rule_engine.apply_to_all(sheet_transactions)
        
        # Sync the updated transactions back to Google Sheets
        sync_result = sheets_client.sync_transactions(sheet_transactions, clear_first=True)
        
        # Also update the monthly summary
        sheets_client.create_monthly_summary(sheet_transactions)
        
        if 'error' in sync_result:
            return jsonify({'success': False, 'error': sync_result['error']})
        
        return jsonify({
            'success': True,
            'total_transactions': len(sheet_transactions),
            'transactions_updated': updated_count,
            'message': f'Applied rules to {len(sheet_transactions)} transactions. {updated_count} were updated.'
        })
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({'success': False, 'error': str(e)})


@app.route('/api/apply-sweep-to-sheets', methods=['POST'])
def api_apply_sweep_to_sheets():
    """
    Load ALL transactions from Google Sheets, apply all sweep rules to remove matching transactions,
    and sync the filtered transactions back to Google Sheets.
    """
    try:
        from backend.sheets.sheets_client import SheetsClient as LocalSheetsClient
        sheets_client = LocalSheetsClient()
        
        if not sheets_client.is_connected():
            return jsonify({
                'success': False,
                'error': sheets_client.last_error or 'Google Sheets not configured. Please complete setup first.'
            })
        
        # Load ALL transactions from Google Sheets (no date filter)
        result = sheets_client.load_transactions(start_date=None)
        
        if 'error' in result and result['error']:
            return jsonify({'success': False, 'error': result['error']})
        
        sheet_transactions = result.get('transactions', [])
        
        if len(sheet_transactions) == 0:
            return jsonify({
                'success': False,
                'error': 'No transactions found in Google Sheets'
            })
        
        original_count = len(sheet_transactions)
        
        # Apply all sweep rules to remove matching transactions
        remaining_transactions, swept_count = exclusion_engine.sweep_transactions(sheet_transactions)
        
        # Sync the filtered transactions back to Google Sheets
        sync_result = sheets_client.sync_transactions(remaining_transactions, clear_first=True)
        
        # Also update the monthly summary with remaining transactions
        sheets_client.create_monthly_summary(remaining_transactions)
        
        if 'error' in sync_result:
            return jsonify({'success': False, 'error': sync_result['error']})
        
        return jsonify({
            'success': True,
            'original_count': original_count,
            'swept_count': swept_count,
            'remaining_count': len(remaining_transactions),
            'message': f'Swept {swept_count} transactions from Google Sheets. {len(remaining_transactions)} remaining.'
        })
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({'success': False, 'error': str(e)})




@app.route('/api/budget-data')
def api_budget_data():
    """API endpoint for budget page data.
    
    Returns income, spending, recurring expenses, needs expenses, and expense list
    for the specified date range.
    """
    from datetime import datetime
    
    start_date = request.args.get('start_date')
    end_date = request.args.get('end_date')
    
    if not start_date or not end_date:
        return jsonify({'error': 'start_date and end_date are required'}), 400
    
    try:
        start = datetime.strptime(start_date, '%Y-%m-%d').date()
        end = datetime.strptime(end_date, '%Y-%m-%d').date()
    except ValueError:
        return jsonify({'error': 'Invalid date format. Use YYYY-MM-DD'}), 400
    
    # Filter transactions by date range
    filtered = [t for t in all_transactions if start <= t.transaction_date.date() <= end]
    
    # Calculate totals
    expenses = [t for t in filtered if t.is_expense]
    income_transactions = [t for t in filtered if t.is_income]
    
    total_income = sum(t.amount for t in income_transactions)
    total_spent = sum(abs(t.amount) for t in expenses)
    
    # Calculate recurring expenses (Subscription + Recurring)
    recurring_expenses = [t for t in expenses if getattr(t, 'recurrence', 'One-time') in ['Subscription', 'Recurring']]
    recurring_total = sum(abs(t.amount) for t in recurring_expenses)
    
    # Calculate needs expenses
    needs_expenses = [t for t in expenses if getattr(t, 'necessity', 'Unknown') == 'Needs']
    needs_total = sum(abs(t.amount) for t in needs_expenses)
    
    # Build expense list with all needed info
    expense_list = []
    for t in sorted(expenses, key=lambda x: x.transaction_date, reverse=True):
        expense_list.append({
            'description': t.description,
            'amount': t.amount,
            'date': t.transaction_date.strftime('%b %d'),
            'fullDate': t.transaction_date.strftime('%Y-%m-%d'),
            'category': t.category,
            'bank': getattr(t, 'bank', ''),
            'necessity': getattr(t, 'necessity', 'Unknown'),
            'recurrence': getattr(t, 'recurrence', 'One-time'),
            'note': getattr(t, 'note', '')
        })
    
    return jsonify({
        'total_income': round(total_income, 2),
        'total_spent': round(total_spent, 2),
        'recurring_total': round(recurring_total, 2),
        'needs_total': round(needs_total, 2),
        'expense_count': len(expenses),
        'income_count': len(income_transactions),
        'expenses': expense_list
    })


# =========================================================================
# RECURRING EXPENSES API ENDPOINTS
# =========================================================================

@app.route('/api/recurring-expenses', methods=['GET'])
def api_get_recurring_expenses():
    """Get all recurring expenses."""
    expenses = recurring_expense_engine.get_all_expenses()
    totals = recurring_expense_engine.get_totals_by_frequency()
    
    return jsonify({
        'expenses': [e.to_dict() for e in expenses],
        'totals': totals
    })


@app.route('/api/recurring-expenses', methods=['POST'])
def api_create_recurring_expense():
    """Create a new recurring expense."""
    data = request.get_json()
    
    if not data:
        return jsonify({'error': 'No data provided'}), 400
    
    name = data.get('name', '').strip()
    amount = data.get('amount', 0)
    frequency = data.get('frequency', 'monthly')
    keywords = data.get('keywords', [])
    category = data.get('category', 'Other')
    
    if not name:
        return jsonify({'error': 'Name is required'}), 400
    
    try:
        amount = float(amount)
    except (ValueError, TypeError):
        return jsonify({'error': 'Invalid amount'}), 400
    
    if amount <= 0:
        return jsonify({'error': 'Amount must be greater than 0'}), 400
    
    if frequency not in ['weekly', 'monthly']:
        frequency = 'monthly'
    
    # Clean up keywords
    if keywords:
        keywords = [k.strip() for k in keywords if k.strip()]
    
    # Create the expense
    expense = recurring_expense_engine.add_expense(
        name=name,
        amount=amount,
        frequency=frequency,
        keywords=keywords,
        category=category
    )
    
    # If keywords provided, link to existing transactions
    linked_count = 0
    if keywords:
        linked_count = recurring_expense_engine.link_to_transactions(expense, all_transactions)
    
    return jsonify({
        'success': True,
        'expense': expense.to_dict(),
        'linked_count': linked_count
    })


@app.route('/api/recurring-expenses/<expense_id>', methods=['PUT'])
def api_update_recurring_expense(expense_id):
    """Update an existing recurring expense."""
    data = request.get_json()
    
    if not data:
        return jsonify({'error': 'No data provided'}), 400
    
    name = data.get('name')
    amount = data.get('amount')
    frequency = data.get('frequency')
    keywords = data.get('keywords')
    enabled = data.get('enabled')
    category = data.get('category')
    
    # Validate amount if provided
    if amount is not None:
        try:
            amount = float(amount)
        except (ValueError, TypeError):
            return jsonify({'error': 'Invalid amount'}), 400
    
    # Clean up keywords if provided
    if keywords is not None:
        keywords = [k.strip() for k in keywords if k.strip()]
    
    expense = recurring_expense_engine.update_expense(
        expense_id,
        name=name,
        amount=amount,
        frequency=frequency,
        keywords=keywords,
        enabled=enabled,
        category=category
    )
    
    if not expense:
        return jsonify({'error': 'Expense not found'}), 404
    
    # Re-link to transactions if keywords changed
    linked_count = 0
    if keywords is not None and expense.keywords:
        linked_count = recurring_expense_engine.link_to_transactions(expense, all_transactions)
    
    return jsonify({
        'success': True,
        'expense': expense.to_dict(),
        'linked_count': linked_count
    })


@app.route('/api/recurring-expenses/<expense_id>', methods=['DELETE'])
def api_delete_recurring_expense(expense_id):
    """Delete a recurring expense."""
    success = recurring_expense_engine.delete_expense(expense_id)
    
    if not success:
        return jsonify({'error': 'Expense not found'}), 404
    
    return jsonify({'success': True})


@app.route('/api/recurring-expenses/preview', methods=['POST'])
def api_preview_recurring_expense():
    """Preview which transactions would match given keywords."""
    data = request.get_json()
    
    if not data:
        return jsonify({'error': 'No data provided'}), 400
    
    keywords = data.get('keywords', [])
    
    if not keywords or not isinstance(keywords, list):
        return jsonify({'count': 0, 'samples': []})
    
    # Clean up keywords
    keywords = [k.strip() for k in keywords if k.strip()]
    
    if not keywords:
        return jsonify({'count': 0, 'samples': []})
    
    result = recurring_expense_engine.preview_matches(keywords, all_transactions)
    
    return jsonify(result)


@app.route('/api/recurring-expenses/link-all', methods=['POST'])
def api_link_all_recurring_expenses():
    """Link all recurring expenses to matching transactions."""
    linked_count = recurring_expense_engine.link_all_expenses(all_transactions)
    
    return jsonify({
        'success': True,
        'linked_count': linked_count
    })


@app.route('/settings')
def settings_page():
    """Settings page with diagnostics, rules management, and category management."""
    return render_template('settings.html')


@app.route('/api/reset-sheets-config', methods=['POST'])
def api_reset_sheets_config():
    """Delete credentials.json and reset Google Sheets configuration."""
    try:
        # Delete credentials.json if it exists
        if Config.GOOGLE_CREDENTIALS_PATH.exists():
            Config.GOOGLE_CREDENTIALS_PATH.unlink()
        
        # Delete .env file to force setup wizard (relative to base directory)
        env_file = BASE_DIR / '.env'
        if env_file.exists():
            env_file.unlink()
        
        return jsonify({
            'success': True,
            'message': 'Configuration reset. Redirecting to setup wizard...'
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        })


@app.route('/api/clear-transactions', methods=['POST'])
def api_clear_transactions():
    """Clear all transactions from memory."""
    global all_transactions
    count = len(all_transactions)
    all_transactions = []
    return jsonify({
        'success': True,
        'cleared_count': count,
        'message': f'Cleared {count} transactions from memory'
    })


@app.route('/api/deduplicate', methods=['POST'])
def api_deduplicate_transactions():
    """Remove duplicate transactions from memory and optionally from Google Sheets."""
    global all_transactions
    
    if len(all_transactions) == 0:
        return jsonify({
            'success': True,
            'duplicates_removed': 0,
            'message': 'No transactions to deduplicate'
        })
    
    # Track seen transactions using key fields (date, description, amount, bank)
    seen_keys = set()
    unique_transactions = []
    duplicates_removed = 0
    
    for t in all_transactions:
        # Create a key based on unique identifying fields
        key = (
            t.transaction_date.strftime('%Y-%m-%d'),
            t.description,
            round(t.amount, 2),  # Round to avoid float precision issues
            t.bank
        )
        
        if key not in seen_keys:
            seen_keys.add(key)
            unique_transactions.append(t)
        else:
            duplicates_removed += 1
    
    # Update the global transactions list
    all_transactions = unique_transactions
    
    # Also re-sync to Google Sheets if connected (clear and re-upload deduplicated data)
    sheets_synced = False
    if duplicates_removed > 0:
        try:
            sheets_client = SheetsClient()
            if sheets_client.is_connected():
                sync_result = sheets_client.sync_transactions(all_transactions, clear_first=True)
                sheets_client.create_monthly_summary(all_transactions)
                sheets_synced = 'error' not in sync_result
        except Exception as e:
            print(f"Warning: Could not sync deduplicated data to Sheets: {e}")
    
    return jsonify({
        'success': True,
        'duplicates_removed': duplicates_removed,
        'remaining_transactions': len(all_transactions),
        'sheets_synced': sheets_synced,
        'message': f'Removed {duplicates_removed} duplicate(s). {len(all_transactions)} unique transactions remain.'
    })


@app.route('/api/tag-values')
def api_get_all_tag_values():
    """Get all unique categories, necessities, recurrences used in transactions with counts."""
    from collections import Counter
    
    categories = Counter()
    necessities = Counter()
    recurrences = Counter()
    
    for t in all_transactions:
        if t.category:
            categories[t.category] += 1
        if hasattr(t, 'necessity') and t.necessity:
            necessities[t.necessity] += 1
        if hasattr(t, 'recurrence') and t.recurrence:
            recurrences[t.recurrence] += 1
    
    return jsonify({
        'categories': [{'name': k, 'count': v} for k, v in sorted(categories.items())],
        'necessities': [{'name': k, 'count': v} for k, v in sorted(necessities.items())],
        'recurrences': [{'name': k, 'count': v} for k, v in sorted(recurrences.items())],
        'transaction_count': len(all_transactions)
    })


@app.route('/api/rename-tag', methods=['POST'])
def api_rename_tag():
    """Rename a tag/category across all transactions and rules."""
    data = request.get_json()
    
    if not data:
        return jsonify({'error': 'No data provided'}), 400
    
    field = data.get('field', 'category').strip()
    old_value = data.get('old_value', '').strip()
    new_value = data.get('new_value', '').strip()
    
    if not old_value or not new_value:
        return jsonify({'error': 'Both old and new values are required'}), 400
    
    if old_value == new_value:
        return jsonify({'error': 'Old and new values are the same'}), 400
    
    # Allowed fields to rename
    allowed_fields = ['category', 'necessity', 'recurrence']
    if field not in allowed_fields:
        return jsonify({'error': f'Invalid field: {field}'}), 400
    
    # Count updates
    transactions_updated = 0
    rules_updated = 0
    
    # Update all transactions
    for t in all_transactions:
        if hasattr(t, field) and getattr(t, field) == old_value:
            setattr(t, field, new_value)
            transactions_updated += 1
    
    # Update category rules if the field matches
    for rule in rule_engine.get_all_rules():
        if rule.field == field and rule.category == old_value:
            rule_engine.update_rule(rule.id, category=new_value)
            rules_updated += 1
    
    return jsonify({
        'success': True,
        'field': field,
        'old_value': old_value,
        'new_value': new_value,
        'transactions_updated': transactions_updated,
        'rules_updated': rules_updated
    })


@app.route('/api/add-tag', methods=['POST'])
def api_add_tag():
    """Add a new tag value to specific transactions (or just register it for future use)."""
    data = request.get_json()
    
    if not data:
        return jsonify({'error': 'No data provided'}), 400
    
    field = data.get('field', 'category').strip()
    value = data.get('value', '').strip()
    
    if not value:
        return jsonify({'error': 'Tag value is required'}), 400
    
    allowed_fields = ['category', 'necessity', 'recurrence']
    if field not in allowed_fields:
        return jsonify({'error': f'Invalid field: {field}'}), 400
    
    # The tag is now "registered" - it will appear when used
    # For now, we just return success. The tag will be visible once applied to transactions.
    return jsonify({
        'success': True,
        'field': field,
        'value': value,
        'message': f'Tag "{value}" is ready to use. Apply it to transactions via auto-tag rules or manual editing.'
    })


@app.route('/api/delete-tag', methods=['POST'])
def api_delete_tag():
    """Reset a tag value to 'Unknown' or 'Other' across all transactions."""
    data = request.get_json()
    
    if not data:
        return jsonify({'error': 'No data provided'}), 400
    
    field = data.get('field', 'category').strip()
    value = data.get('value', '').strip()
    
    if not value:
        return jsonify({'error': 'Value is required'}), 400
    
    # Determine the default value for each field
    default_values = {
        'category': 'Other',
        'necessity': 'Unknown',
        'recurrence': 'Unknown'
    }
    
    if field not in default_values:
        return jsonify({'error': f'Invalid field: {field}'}), 400
    
    default = default_values[field]
    transactions_updated = 0
    
    # Update all transactions with this value
    for t in all_transactions:
        if hasattr(t, field) and getattr(t, field) == value:
            setattr(t, field, default)
            transactions_updated += 1
    
    return jsonify({
        'success': True,
        'field': field,
        'value': value,
        'reset_to': default,
        'transactions_updated': transactions_updated
    })


@app.route('/api/sync-diagnostics')
def api_sync_diagnostics():
    """Get diagnostic information for Google Sheets sync."""
    diagnostics = {
        'transactions_in_memory': len(all_transactions),
        'expense_count': len([t for t in all_transactions if t.is_expense]),
        'income_count': len([t for t in all_transactions if t.is_income]),
        'sheets_configured': False,
        'credentials_exist': False,
        'sheet_id': None,
        'connection_status': 'unknown',
        'connection_error': None,
        'last_test': None
    }
    
    # Check credentials file
    diagnostics['credentials_exist'] = Config.GOOGLE_CREDENTIALS_PATH.exists()
    diagnostics['credentials_path'] = str(Config.GOOGLE_CREDENTIALS_PATH)
    
    # Check sheet ID
    if Config.GOOGLE_SHEETS_ID and Config.GOOGLE_SHEETS_ID.strip():
        diagnostics['sheet_id'] = Config.GOOGLE_SHEETS_ID
        diagnostics['sheet_id_preview'] = Config.GOOGLE_SHEETS_ID[:10] + '...' if len(Config.GOOGLE_SHEETS_ID) > 10 else Config.GOOGLE_SHEETS_ID
    
    # Test connection
    if diagnostics['credentials_exist'] and diagnostics['sheet_id']:
        diagnostics['sheets_configured'] = True
        try:
            sheets_client = SheetsClient()
            if sheets_client.is_connected():
                diagnostics['connection_status'] = 'connected'
                # Try to get sheet title
                try:
                    diagnostics['sheet_title'] = sheets_client.spreadsheet.title
                except:
                    pass
            else:
                diagnostics['connection_status'] = 'failed'
                # Use the detailed error from SheetsClient if available
                diagnostics['connection_error'] = getattr(sheets_client, 'last_error', None) or 'Could not connect to spreadsheet'
        except Exception as e:
            diagnostics['connection_status'] = 'error'
            diagnostics['connection_error'] = str(e) if str(e) else f'{type(e).__name__}'
    else:
        if not diagnostics['credentials_exist']:
            diagnostics['connection_error'] = 'credentials.json file not found'
        elif not diagnostics['sheet_id']:
            diagnostics['connection_error'] = 'Google Sheet ID not configured'
    
    from datetime import datetime
    diagnostics['last_test'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    
    return jsonify(diagnostics)


# =================== PERIOD NOTES API ===================

@app.route('/api/period-notes/<period_key>', methods=['GET'])
def api_get_period_note(period_key):
    """Get the personal analysis note for a specific period."""
    content = period_notes_engine.get_note(period_key)
    return jsonify({
        'period_key': period_key,
        'content': content
    })


@app.route('/api/period-notes/<period_key>', methods=['POST', 'PUT'])
def api_save_period_note(period_key):
    """Save or update the personal analysis note for a specific period."""
    data = request.get_json()
    
    if not data:
        return jsonify({'error': 'No data provided'}), 400
    
    content = data.get('content', '')
    
    # Save the note
    note = period_notes_engine.save_note(period_key, content)
    
    return jsonify({
        'success': True,
        'period_key': note.period_key,
        'content': note.content
    })


@app.route('/api/period-notes/<period_key>', methods=['DELETE'])
def api_delete_period_note(period_key):
    """Delete the personal analysis note for a specific period."""
    success = period_notes_engine.delete_note(period_key)
    
    return jsonify({
        'success': success,
        'period_key': period_key
    })


@app.route('/api/period-notes', methods=['GET'])
def api_get_all_period_notes():
    """Get all personal analysis notes."""
    notes = period_notes_engine.get_all_notes()
    return jsonify({
        'notes': notes
    })


@app.route('/api/period-notes/export', methods=['GET'])
def api_export_period_notes():
    """Export all personal analysis notes as JSON."""
    try:
        notes = period_notes_engine.get_all_notes()
        
        # Convert to list format for export
        notes_list = [
            {'period_key': key, 'content': content}
            for key, content in notes.items()
            if content.strip()  # Only export non-empty notes
        ]
        
        export_data = {
            'version': '1.0',
            'exported_at': __import__('datetime').datetime.now().isoformat(),
            'personal_analysis_notes': notes_list
        }
        
        return jsonify(export_data)
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/period-notes/import', methods=['POST'])
def api_import_period_notes():
    """Import personal analysis notes from JSON."""
    try:
        data = request.get_json()
        
        if not data:
            return jsonify({'error': 'No data provided'}), 400
        
        notes_list = data.get('personal_analysis_notes', [])
        
        if not notes_list:
            return jsonify({'error': 'No notes found in import data'}), 400
        
        imported_count = 0
        skipped_count = 0
        
        for note in notes_list:
            period_key = note.get('period_key', '')
            content = note.get('content', '')
            
            if not period_key or not content.strip():
                skipped_count += 1
                continue
            
            # Check if note already exists
            existing = period_notes_engine.get_note(period_key)
            if existing and existing.strip():
                # Don't overwrite existing notes
                skipped_count += 1
                continue
            
            period_notes_engine.save_note(period_key, content)
            imported_count += 1
        
        return jsonify({
            'success': True,
            'imported': imported_count,
            'skipped': skipped_count
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 500


if __name__ == '__main__':
    app.run(
        host='0.0.0.0',
        port=Config.PORT,
        debug=Config.DEBUG
    )

